# config.yaml

# Model
# model_name: meta-llama/Llama-3.2-3B-Instruct
# model_name: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
model_name: deepseek-ai/DeepSeek-R1-Distill-Llama-8B

# Training / Inference
precision: bfloat16
batch_size: 96
max_new_tokens: 512 # Effective max length
temperature: 0.7
top_p: 0.95
do_sample: false
early_stopping: true
repetition_penalty: 1.0
num_beams: 3

# Dataset
dataset_name: gsm8k
split: "train"

# Paths
checkpoint_dir: checkpoints/
output_file: deepseek.jsonl

# Optional: CUDA config (uncomment to use)
# cuda_visible_devices: "3,4,5"
