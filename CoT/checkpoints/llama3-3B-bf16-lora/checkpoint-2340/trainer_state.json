{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 150000,
  "global_step": 2340,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10683760683760683,
      "grad_norm": 0.6868460178375244,
      "learning_rate": 0.0001,
      "loss": 1.26,
      "step": 50
    },
    {
      "epoch": 0.21367521367521367,
      "grad_norm": 0.5379459857940674,
      "learning_rate": 0.0002,
      "loss": 1.0035,
      "step": 100
    },
    {
      "epoch": 0.32051282051282054,
      "grad_norm": 0.4919361472129822,
      "learning_rate": 0.00019553571428571428,
      "loss": 0.9592,
      "step": 150
    },
    {
      "epoch": 0.42735042735042733,
      "grad_norm": 0.5242490172386169,
      "learning_rate": 0.00019107142857142858,
      "loss": 0.931,
      "step": 200
    },
    {
      "epoch": 0.5341880341880342,
      "grad_norm": 0.5008779168128967,
      "learning_rate": 0.00018660714285714287,
      "loss": 0.9354,
      "step": 250
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 0.47127431631088257,
      "learning_rate": 0.00018214285714285714,
      "loss": 0.9235,
      "step": 300
    },
    {
      "epoch": 0.7478632478632479,
      "grad_norm": 0.5137622952461243,
      "learning_rate": 0.00017767857142857141,
      "loss": 0.9269,
      "step": 350
    },
    {
      "epoch": 0.8547008547008547,
      "grad_norm": 0.4657340943813324,
      "learning_rate": 0.00017321428571428574,
      "loss": 0.9293,
      "step": 400
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 0.5761339664459229,
      "learning_rate": 0.00016875,
      "loss": 0.9182,
      "step": 450
    },
    {
      "epoch": 1.0683760683760684,
      "grad_norm": 0.5756275057792664,
      "learning_rate": 0.00016428571428571428,
      "loss": 0.9137,
      "step": 500
    },
    {
      "epoch": 1.1752136752136753,
      "grad_norm": 0.5443236231803894,
      "learning_rate": 0.00015982142857142858,
      "loss": 0.89,
      "step": 550
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 0.5031188130378723,
      "learning_rate": 0.00015535714285714287,
      "loss": 0.9149,
      "step": 600
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 0.523789644241333,
      "learning_rate": 0.00015089285714285714,
      "loss": 0.8936,
      "step": 650
    },
    {
      "epoch": 1.4957264957264957,
      "grad_norm": 0.5200883746147156,
      "learning_rate": 0.00014642857142857141,
      "loss": 0.8971,
      "step": 700
    },
    {
      "epoch": 1.6025641025641026,
      "grad_norm": 0.5754552483558655,
      "learning_rate": 0.00014196428571428574,
      "loss": 0.8942,
      "step": 750
    },
    {
      "epoch": 1.7094017094017095,
      "grad_norm": 0.559182345867157,
      "learning_rate": 0.0001375,
      "loss": 0.8964,
      "step": 800
    },
    {
      "epoch": 1.8162393162393162,
      "grad_norm": 0.4949803352355957,
      "learning_rate": 0.00013303571428571428,
      "loss": 0.894,
      "step": 850
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.5599374175071716,
      "learning_rate": 0.00012857142857142858,
      "loss": 0.9049,
      "step": 900
    },
    {
      "epoch": 2.02991452991453,
      "grad_norm": 0.5559551119804382,
      "learning_rate": 0.00012410714285714287,
      "loss": 0.8816,
      "step": 950
    },
    {
      "epoch": 2.1367521367521367,
      "grad_norm": 0.5808320045471191,
      "learning_rate": 0.00011964285714285714,
      "loss": 0.8858,
      "step": 1000
    },
    {
      "epoch": 2.2435897435897436,
      "grad_norm": 0.5770097970962524,
      "learning_rate": 0.00011517857142857143,
      "loss": 0.8848,
      "step": 1050
    },
    {
      "epoch": 2.3504273504273505,
      "grad_norm": 0.5930321216583252,
      "learning_rate": 0.00011071428571428572,
      "loss": 0.8639,
      "step": 1100
    },
    {
      "epoch": 2.4572649572649574,
      "grad_norm": 0.5751217603683472,
      "learning_rate": 0.00010625000000000001,
      "loss": 0.8682,
      "step": 1150
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 0.562564492225647,
      "learning_rate": 0.00010178571428571428,
      "loss": 0.877,
      "step": 1200
    },
    {
      "epoch": 2.6709401709401708,
      "grad_norm": 0.5625511407852173,
      "learning_rate": 9.732142857142858e-05,
      "loss": 0.8697,
      "step": 1250
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.6637820601463318,
      "learning_rate": 9.285714285714286e-05,
      "loss": 0.8638,
      "step": 1300
    },
    {
      "epoch": 2.8846153846153846,
      "grad_norm": 0.5892887115478516,
      "learning_rate": 8.839285714285714e-05,
      "loss": 0.8531,
      "step": 1350
    },
    {
      "epoch": 2.9914529914529915,
      "grad_norm": 0.6365827918052673,
      "learning_rate": 8.392857142857144e-05,
      "loss": 0.8567,
      "step": 1400
    },
    {
      "epoch": 3.0982905982905984,
      "grad_norm": 0.6761068105697632,
      "learning_rate": 7.946428571428571e-05,
      "loss": 0.8369,
      "step": 1450
    },
    {
      "epoch": 3.2051282051282053,
      "grad_norm": 0.7051236033439636,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.8483,
      "step": 1500
    },
    {
      "epoch": 3.3119658119658117,
      "grad_norm": 0.6383886337280273,
      "learning_rate": 7.053571428571429e-05,
      "loss": 0.8271,
      "step": 1550
    },
    {
      "epoch": 3.4188034188034186,
      "grad_norm": 0.7242798805236816,
      "learning_rate": 6.607142857142857e-05,
      "loss": 0.8234,
      "step": 1600
    },
    {
      "epoch": 3.5256410256410255,
      "grad_norm": 0.6500551104545593,
      "learning_rate": 6.160714285714286e-05,
      "loss": 0.8495,
      "step": 1650
    },
    {
      "epoch": 3.6324786324786325,
      "grad_norm": 0.703376054763794,
      "learning_rate": 5.714285714285714e-05,
      "loss": 0.861,
      "step": 1700
    },
    {
      "epoch": 3.7393162393162394,
      "grad_norm": 0.6551074981689453,
      "learning_rate": 5.267857142857143e-05,
      "loss": 0.8616,
      "step": 1750
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 0.7041062712669373,
      "learning_rate": 4.8214285714285716e-05,
      "loss": 0.8295,
      "step": 1800
    },
    {
      "epoch": 3.952991452991453,
      "grad_norm": 0.712709903717041,
      "learning_rate": 4.375e-05,
      "loss": 0.8416,
      "step": 1850
    },
    {
      "epoch": 4.05982905982906,
      "grad_norm": 0.6716057658195496,
      "learning_rate": 3.928571428571429e-05,
      "loss": 0.8343,
      "step": 1900
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.7720338106155396,
      "learning_rate": 3.4821428571428574e-05,
      "loss": 0.8215,
      "step": 1950
    },
    {
      "epoch": 4.273504273504273,
      "grad_norm": 0.7388700246810913,
      "learning_rate": 3.0357142857142857e-05,
      "loss": 0.8246,
      "step": 2000
    },
    {
      "epoch": 4.380341880341881,
      "grad_norm": 0.6783739328384399,
      "learning_rate": 2.5892857142857148e-05,
      "loss": 0.8157,
      "step": 2050
    },
    {
      "epoch": 4.487179487179487,
      "grad_norm": 0.826016366481781,
      "learning_rate": 2.1428571428571428e-05,
      "loss": 0.824,
      "step": 2100
    },
    {
      "epoch": 4.594017094017094,
      "grad_norm": 0.708844780921936,
      "learning_rate": 1.6964285714285715e-05,
      "loss": 0.7972,
      "step": 2150
    },
    {
      "epoch": 4.700854700854701,
      "grad_norm": 0.6929633617401123,
      "learning_rate": 1.25e-05,
      "loss": 0.8138,
      "step": 2200
    },
    {
      "epoch": 4.8076923076923075,
      "grad_norm": 0.842689037322998,
      "learning_rate": 8.035714285714286e-06,
      "loss": 0.8268,
      "step": 2250
    },
    {
      "epoch": 4.914529914529915,
      "grad_norm": 0.7214968800544739,
      "learning_rate": 3.5714285714285714e-06,
      "loss": 0.8173,
      "step": 2300
    }
  ],
  "logging_steps": 50,
  "max_steps": 2340,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 150000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7995867233110016e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
