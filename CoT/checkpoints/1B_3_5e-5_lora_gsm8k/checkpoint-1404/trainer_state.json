{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 150000,
  "global_step": 1404,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10683760683760683,
      "grad_norm": 0.8011690974235535,
      "learning_rate": 2.5e-05,
      "loss": 1.0977,
      "step": 50
    },
    {
      "epoch": 0.21367521367521367,
      "grad_norm": 0.7951686978340149,
      "learning_rate": 5e-05,
      "loss": 0.9032,
      "step": 100
    },
    {
      "epoch": 0.32051282051282054,
      "grad_norm": 0.7413551211357117,
      "learning_rate": 4.8082822085889575e-05,
      "loss": 0.7632,
      "step": 150
    },
    {
      "epoch": 0.42735042735042733,
      "grad_norm": 0.9235429763793945,
      "learning_rate": 4.616564417177914e-05,
      "loss": 0.7437,
      "step": 200
    },
    {
      "epoch": 0.5341880341880342,
      "grad_norm": 0.9064664244651794,
      "learning_rate": 4.424846625766871e-05,
      "loss": 0.723,
      "step": 250
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 0.8929123282432556,
      "learning_rate": 4.2331288343558284e-05,
      "loss": 0.7059,
      "step": 300
    },
    {
      "epoch": 0.7478632478632479,
      "grad_norm": 0.8694618940353394,
      "learning_rate": 4.0414110429447856e-05,
      "loss": 0.713,
      "step": 350
    },
    {
      "epoch": 0.8547008547008547,
      "grad_norm": 1.08974289894104,
      "learning_rate": 3.849693251533742e-05,
      "loss": 0.7097,
      "step": 400
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 0.9924755096435547,
      "learning_rate": 3.6579754601226994e-05,
      "loss": 0.6888,
      "step": 450
    },
    {
      "epoch": 1.0683760683760684,
      "grad_norm": 0.9418225884437561,
      "learning_rate": 3.4662576687116566e-05,
      "loss": 0.6968,
      "step": 500
    },
    {
      "epoch": 1.1752136752136753,
      "grad_norm": 0.9452055096626282,
      "learning_rate": 3.274539877300614e-05,
      "loss": 0.687,
      "step": 550
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 1.023636817932129,
      "learning_rate": 3.0828220858895703e-05,
      "loss": 0.684,
      "step": 600
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 0.9465326070785522,
      "learning_rate": 2.8911042944785276e-05,
      "loss": 0.6741,
      "step": 650
    },
    {
      "epoch": 1.4957264957264957,
      "grad_norm": 1.1436039209365845,
      "learning_rate": 2.6993865030674848e-05,
      "loss": 0.6825,
      "step": 700
    },
    {
      "epoch": 1.6025641025641026,
      "grad_norm": 1.1392163038253784,
      "learning_rate": 2.5076687116564416e-05,
      "loss": 0.6854,
      "step": 750
    },
    {
      "epoch": 1.7094017094017095,
      "grad_norm": 1.0878968238830566,
      "learning_rate": 2.315950920245399e-05,
      "loss": 0.6774,
      "step": 800
    },
    {
      "epoch": 1.8162393162393162,
      "grad_norm": 1.0342103242874146,
      "learning_rate": 2.1242331288343557e-05,
      "loss": 0.6786,
      "step": 850
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.9939375519752502,
      "learning_rate": 1.932515337423313e-05,
      "loss": 0.6868,
      "step": 900
    },
    {
      "epoch": 2.02991452991453,
      "grad_norm": 1.0702100992202759,
      "learning_rate": 1.7407975460122698e-05,
      "loss": 0.6803,
      "step": 950
    },
    {
      "epoch": 2.1367521367521367,
      "grad_norm": 1.0571389198303223,
      "learning_rate": 1.549079754601227e-05,
      "loss": 0.6644,
      "step": 1000
    },
    {
      "epoch": 2.2435897435897436,
      "grad_norm": 1.0824464559555054,
      "learning_rate": 1.357361963190184e-05,
      "loss": 0.6659,
      "step": 1050
    },
    {
      "epoch": 2.3504273504273505,
      "grad_norm": 1.118688702583313,
      "learning_rate": 1.1656441717791411e-05,
      "loss": 0.6875,
      "step": 1100
    },
    {
      "epoch": 2.4572649572649574,
      "grad_norm": 1.0498590469360352,
      "learning_rate": 9.739263803680983e-06,
      "loss": 0.6692,
      "step": 1150
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 1.07725989818573,
      "learning_rate": 7.822085889570554e-06,
      "loss": 0.6701,
      "step": 1200
    },
    {
      "epoch": 2.6709401709401708,
      "grad_norm": 0.8917688131332397,
      "learning_rate": 5.9049079754601225e-06,
      "loss": 0.6693,
      "step": 1250
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 1.207136631011963,
      "learning_rate": 3.987730061349693e-06,
      "loss": 0.6724,
      "step": 1300
    },
    {
      "epoch": 2.8846153846153846,
      "grad_norm": 1.0228875875473022,
      "learning_rate": 2.070552147239264e-06,
      "loss": 0.658,
      "step": 1350
    },
    {
      "epoch": 2.9914529914529915,
      "grad_norm": 1.1059986352920532,
      "learning_rate": 1.5337423312883438e-07,
      "loss": 0.6587,
      "step": 1400
    }
  ],
  "logging_steps": 50,
  "max_steps": 1404,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 150000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.999484741076992e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
