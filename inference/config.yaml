# config.yaml

# Model
model_name: meta-llama/Llama-3.2-1B
# model_name: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B

use_lora: true
weights_path: /home/ubuntu/reasonix/training/checkpoints/1B_3_5e-5_lora_gsm8k/final_model #/home/ubuntu/reasonix/training/checkpoints/llama3-3B_2025-03-31_23-13-23/final_model #/home/ubuntu/reasonix/training/checkpoints/llama3-3B-bf16-lora/final_model

# Training / Inference
precision: float16 #bfloat16
batch_size: 48
max_new_tokens: 512 # Effective max length
temperature: 0.7
top_p: 0.95
do_sample: false
early_stopping: true
repetition_penalty: 1.0
num_beams: 3

# Dataset
dataset_name: gsm8k

# Paths
checkpoint_dir: /home/ubuntu/reasonix/inference/checkpoints/
output_file_name: outputs.txt

# Optional: CUDA config (uncomment to use)
# cuda_visible_devices: "3,4,5"
