{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 150000,
  "global_step": 2340,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10683760683760683,
      "grad_norm": 0.7683691382408142,
      "learning_rate": 2.5e-05,
      "loss": 1.3989,
      "step": 50
    },
    {
      "epoch": 0.21367521367521367,
      "grad_norm": 0.5178767442703247,
      "learning_rate": 5e-05,
      "loss": 1.1258,
      "step": 100
    },
    {
      "epoch": 0.32051282051282054,
      "grad_norm": 0.5647225379943848,
      "learning_rate": 4.888392857142857e-05,
      "loss": 0.993,
      "step": 150
    },
    {
      "epoch": 0.42735042735042733,
      "grad_norm": 0.6396893262863159,
      "learning_rate": 4.7767857142857144e-05,
      "loss": 0.9431,
      "step": 200
    },
    {
      "epoch": 0.5341880341880342,
      "grad_norm": 0.6427904367446899,
      "learning_rate": 4.665178571428572e-05,
      "loss": 0.9397,
      "step": 250
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 0.637651801109314,
      "learning_rate": 4.5535714285714286e-05,
      "loss": 0.9195,
      "step": 300
    },
    {
      "epoch": 0.7478632478632479,
      "grad_norm": 0.7857475280761719,
      "learning_rate": 4.4419642857142854e-05,
      "loss": 0.9147,
      "step": 350
    },
    {
      "epoch": 0.8547008547008547,
      "grad_norm": 0.8213043212890625,
      "learning_rate": 4.3303571428571435e-05,
      "loss": 0.9159,
      "step": 400
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 0.8320412039756775,
      "learning_rate": 4.21875e-05,
      "loss": 0.9028,
      "step": 450
    },
    {
      "epoch": 1.0683760683760684,
      "grad_norm": 0.8574076294898987,
      "learning_rate": 4.107142857142857e-05,
      "loss": 0.9049,
      "step": 500
    },
    {
      "epoch": 1.1752136752136753,
      "grad_norm": 0.7859962582588196,
      "learning_rate": 3.9955357142857144e-05,
      "loss": 0.8886,
      "step": 550
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 0.6961268186569214,
      "learning_rate": 3.883928571428572e-05,
      "loss": 0.9106,
      "step": 600
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 0.7360853552818298,
      "learning_rate": 3.7723214285714286e-05,
      "loss": 0.8882,
      "step": 650
    },
    {
      "epoch": 1.4957264957264957,
      "grad_norm": 0.7516083121299744,
      "learning_rate": 3.6607142857142853e-05,
      "loss": 0.8931,
      "step": 700
    },
    {
      "epoch": 1.6025641025641026,
      "grad_norm": 0.8806081414222717,
      "learning_rate": 3.5491071428571435e-05,
      "loss": 0.8899,
      "step": 750
    },
    {
      "epoch": 1.7094017094017095,
      "grad_norm": 0.8108112812042236,
      "learning_rate": 3.4375e-05,
      "loss": 0.8917,
      "step": 800
    },
    {
      "epoch": 1.8162393162393162,
      "grad_norm": 0.7218542098999023,
      "learning_rate": 3.325892857142857e-05,
      "loss": 0.8886,
      "step": 850
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.7790691256523132,
      "learning_rate": 3.2142857142857144e-05,
      "loss": 0.8998,
      "step": 900
    },
    {
      "epoch": 2.02991452991453,
      "grad_norm": 0.7974791526794434,
      "learning_rate": 3.102678571428572e-05,
      "loss": 0.8816,
      "step": 950
    },
    {
      "epoch": 2.1367521367521367,
      "grad_norm": 0.8254654407501221,
      "learning_rate": 2.9910714285714286e-05,
      "loss": 0.8984,
      "step": 1000
    },
    {
      "epoch": 2.2435897435897436,
      "grad_norm": 0.8478738069534302,
      "learning_rate": 2.8794642857142857e-05,
      "loss": 0.898,
      "step": 1050
    },
    {
      "epoch": 2.3504273504273505,
      "grad_norm": 0.8218148946762085,
      "learning_rate": 2.767857142857143e-05,
      "loss": 0.8749,
      "step": 1100
    },
    {
      "epoch": 2.4572649572649574,
      "grad_norm": 0.7827649116516113,
      "learning_rate": 2.6562500000000002e-05,
      "loss": 0.8802,
      "step": 1150
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 0.8130108714103699,
      "learning_rate": 2.544642857142857e-05,
      "loss": 0.888,
      "step": 1200
    },
    {
      "epoch": 2.6709401709401708,
      "grad_norm": 0.8092265129089355,
      "learning_rate": 2.4330357142857144e-05,
      "loss": 0.8812,
      "step": 1250
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.9254025816917419,
      "learning_rate": 2.3214285714285715e-05,
      "loss": 0.876,
      "step": 1300
    },
    {
      "epoch": 2.8846153846153846,
      "grad_norm": 0.7836974859237671,
      "learning_rate": 2.2098214285714286e-05,
      "loss": 0.8646,
      "step": 1350
    },
    {
      "epoch": 2.9914529914529915,
      "grad_norm": 0.8672015070915222,
      "learning_rate": 2.098214285714286e-05,
      "loss": 0.869,
      "step": 1400
    },
    {
      "epoch": 3.0982905982905984,
      "grad_norm": 0.9342238306999207,
      "learning_rate": 1.9866071428571427e-05,
      "loss": 0.866,
      "step": 1450
    },
    {
      "epoch": 3.2051282051282053,
      "grad_norm": 0.9767681956291199,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.8803,
      "step": 1500
    },
    {
      "epoch": 3.3119658119658117,
      "grad_norm": 0.900113582611084,
      "learning_rate": 1.7633928571428573e-05,
      "loss": 0.8572,
      "step": 1550
    },
    {
      "epoch": 3.4188034188034186,
      "grad_norm": 0.9544459581375122,
      "learning_rate": 1.6517857142857144e-05,
      "loss": 0.8528,
      "step": 1600
    },
    {
      "epoch": 3.5256410256410255,
      "grad_norm": 0.9065089821815491,
      "learning_rate": 1.5401785714285715e-05,
      "loss": 0.8785,
      "step": 1650
    },
    {
      "epoch": 3.6324786324786325,
      "grad_norm": 0.92311030626297,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.8911,
      "step": 1700
    },
    {
      "epoch": 3.7393162393162394,
      "grad_norm": 0.8768762946128845,
      "learning_rate": 1.3169642857142858e-05,
      "loss": 0.8904,
      "step": 1750
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 0.9744441509246826,
      "learning_rate": 1.2053571428571429e-05,
      "loss": 0.8592,
      "step": 1800
    },
    {
      "epoch": 3.952991452991453,
      "grad_norm": 0.9847326278686523,
      "learning_rate": 1.09375e-05,
      "loss": 0.8713,
      "step": 1850
    },
    {
      "epoch": 4.05982905982906,
      "grad_norm": 0.8977459669113159,
      "learning_rate": 9.821428571428573e-06,
      "loss": 0.8729,
      "step": 1900
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 0.9928236603736877,
      "learning_rate": 8.705357142857143e-06,
      "loss": 0.8698,
      "step": 1950
    },
    {
      "epoch": 4.273504273504273,
      "grad_norm": 0.9701637029647827,
      "learning_rate": 7.589285714285714e-06,
      "loss": 0.8686,
      "step": 2000
    },
    {
      "epoch": 4.380341880341881,
      "grad_norm": 0.8906431198120117,
      "learning_rate": 6.473214285714287e-06,
      "loss": 0.8615,
      "step": 2050
    },
    {
      "epoch": 4.487179487179487,
      "grad_norm": 1.029659628868103,
      "learning_rate": 5.357142857142857e-06,
      "loss": 0.8675,
      "step": 2100
    },
    {
      "epoch": 4.594017094017094,
      "grad_norm": 0.8726011514663696,
      "learning_rate": 4.241071428571429e-06,
      "loss": 0.8417,
      "step": 2150
    },
    {
      "epoch": 4.700854700854701,
      "grad_norm": 0.8848562240600586,
      "learning_rate": 3.125e-06,
      "loss": 0.86,
      "step": 2200
    },
    {
      "epoch": 4.8076923076923075,
      "grad_norm": 1.0935537815093994,
      "learning_rate": 2.0089285714285715e-06,
      "loss": 0.8716,
      "step": 2250
    },
    {
      "epoch": 4.914529914529915,
      "grad_norm": 0.9155208468437195,
      "learning_rate": 8.928571428571428e-07,
      "loss": 0.8601,
      "step": 2300
    }
  ],
  "logging_steps": 50,
  "max_steps": 2340,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 150000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.8315505865045606e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
