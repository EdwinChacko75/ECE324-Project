# config.yaml
dataset:
  path: /home/ubuntu/reasonix/RLHF/data/test.jsonl  
  split: "train"

model:
  base_model: meta-llama/Llama-3.2-1B
  lora:
  weights_path:
  max_length: 512

training:
  reward_model:
    epochs: 3
    batch_size: 32
    learning_rate: 2e-5
    logging_steps: 50
    save_steps: 200
    evaluation_strategy: "no"
    fp16: true
    bf16: false
    output_dir: "./models/reward_model"

  rlhf:
    epochs: 3
    batch_size: 4
    learning_rate: 1e-5
    output_dir: "./models/rlhf_policy"
    max_new_tokens: 50